{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "julian-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-cache",
   "metadata": {},
   "source": [
    "## **Chapter 1 :Input Reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture('resources/test-video.mp4') # give the correct path here\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    cv.imshow(\"IMAGE\", frame)\n",
    "    \n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acoustic-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0) # give the correct path for default webcam ( zero is for default webcam )\n",
    "cap.set(3, 640) # define the width of the frame\n",
    "cap.set(4, 480) # define the height of the frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "#     # if frame is read correctly ret is True\n",
    "#     if not ret:\n",
    "#         print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "#         break\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    cv.imshow(\"IMAGE\", frame)\n",
    "    \n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-nightmare",
   "metadata": {},
   "source": [
    "## **Chapter 2 :Basic Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medium-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('resources/lena.png')\n",
    "\n",
    "imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # convert image color to gray scale\n",
    "\n",
    "cv.imshow(\"Gray Image\", imgGray)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-instruction",
   "metadata": {},
   "source": [
    "- low pass filters are used to blurring(remove high frequency contents such as noise and edges) while high pass filters are used to edge detection.\n",
    "- **A linear filter** is one that can be done with a `convolution`, which is just the linear sum of values in a sliding window.\n",
    "- **A non-linear filter** is one that cannot be done with `convolution` or Fourier multiplication.\n",
    "\n",
    "1. **Averaging**\n",
    "2. **Gaussian Filtering**\n",
    "3. **Median Filtering**\n",
    "4. **Bilateral Filtering**\n",
    "\n",
    "\n",
    "> ***Averaging***\n",
    "\n",
    "- This is done by convolving the image with a normalized box filter. It simply takes the average of all the pixels under kernel area and replaces the central element with this average. This is done by the function `cv.blur(src img, (kernel,kernel))` or `cv.boxFilter(src img, (kernel,kernel))`. `This also blur the edges`(disadvantage).\n",
    "\n",
    "> ***Gaussian Filtering***\n",
    "\n",
    "- instead of a box filter consisting of equal filter coefficients, a Gaussian kernel is used. It is done with the function, `cv.GaussianBlur(src img, (kernel,kernel),sigmaX,sigmaY)`. We should specify the width and height of the kernel which should be **positive** and **odd**. We also should specify the standard deviation in the X and Y directions, sigmaX and sigmaY respectively. If only sigmaX is specified, sigmaY is taken as equal to sigmaX. If both are given as zeros, they are calculated from the kernel size. Gaussian filtering is highly effective in removing Gaussian noise from the image.\n",
    "- If you want, you can create a Gaussian kernel with the function, `cv.getGaussianKernel()`.\n",
    "\n",
    "> ***Median Filtering***\n",
    "\n",
    "- Non linear filter.\n",
    "- The function `cv.medianBlur(src img, kernel size)` computes the median of all the pixels under the kernel window and the central pixel is replaced with this median value. This is highly effective in removing salt-and-pepper noise which cannot be solved using above filters.\n",
    "- This reduces the noise effectively. The kernel size must be a **positive** odd **integer**.\n",
    "\n",
    "> ***Bilateral Filtering***\n",
    "\n",
    "- Non linear filter\n",
    "- The filters we presented earlier tend to blur edges. This is not the case for the bilateral filter, `cv.bilateralFilter()`, which was defined for, and is highly effective at `noise removal while preserving edges`. But the operation is `slower` compared to other filters. \n",
    "- There is two gaussian functions. Second one is used to add normalized factor and range weight to the first gaussian function that uses for smoothing.\n",
    "    - OpenCV has a function called bilateralFilter() with the following arguments:\n",
    "        - ***d**: Diameter of each pixel neighborhood.*\n",
    "        - ***sigmaColor**: Value of `sigma` in the color space. The greater the value, the colors farther to each other will start to get mixed.*\n",
    "        - ***sigmaColor**: Value of `sigma` in the coordinate space. The greater its value, the more further pixels will mix together, given that their colors lie within the sigmaColor range. (example : `bilateral = cv2.bilateralFilter(img, 15, 75, 75)`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disciplinary-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBlur = cv.GaussianBlur(imgGray, (7,7), 0) # cv.GAussianBlur(src img, (kernel,kernel), sigma)\n",
    "\n",
    "cv.imshow(\"Blur Image\", imgBlur)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-airplane",
   "metadata": {},
   "source": [
    " Edge detection is a technique of image processing used to identify points in a digital image with discontinuities,simply to say, sharp changes in the image brightness. These points where the image brightness varies sharply are called the edges (or boundaries)of the image.There are few techniques for edge detection....... they are\n",
    "\n",
    "1. **Prewitt edge detection**\n",
    "2. **Sobel edge detection**\n",
    "3. **Laplacian edge detection**\n",
    "4. **Canny edge detection** (most commonly used highly effective and complex)\n",
    "\n",
    "\n",
    "> ***Prewitt edge detection***\n",
    "\n",
    "- This method is a commonly used edge detector mostly to detect the horizontal and vertical edges in images. The following are the Prewitt edge detection filters\n",
    "    - **filter for vertical edges(Gx) = [[1, 0, -1], [1, 0, -1], [1, 0, -1]]**          \n",
    "    - **filter for horizontal edges(Gy) = [[1, 1, 1], [0, 0, 0], [-1, -1, -1]]**\n",
    "\n",
    "> ***Sobel edge detection***\n",
    "\n",
    "- This uses a filter that gives more emphasis to the centre of the filter. It is one of the most commonly used edge detectors and helps `reduce noise` and provides differentiating, giving edge response simultaneously. The following are the filters used in this method\n",
    "    - **filter for vertical edges(Gx) = [[1, 0, -1], [2, 0, -2], [1, 0, -1]]**          \n",
    "    - **filter for horizontal edges(Gy) = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]**\n",
    "\n",
    "> ***Laplacian edge detection***\n",
    "\n",
    "- This method uses only one filter (also called a kernel). In a single pass, Laplacian edge detection performs second-order derivatives and hence are sensitive to noise. `To avoid this sensitivity to noise, before applying this method, Gaussian smoothing is performed on the image.`\n",
    "    - **common filter = [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]**   \n",
    "\n",
    "> ***Canny edge detection***\n",
    "\n",
    "- It is a multi-stage algorithm used to detect/identify a wide range of edges. The following are the various stages of the Canny edge detection algorithm-\n",
    "    - *Convert the image to grayscale*\n",
    "    - ***Reduce noise** – as the edge detection that using derivatives is sensitive to noise, we reduce it.*\n",
    "    - ***Calculate the gradient** – Smoothened image is then filtered with a Sobel kernel in both horizontal and vertical direction to get first derivative in horizontal direction ( Gx) and vertical direction ( Gy).Help to find `edge intensity` and `direction`. Gradient direction is always `perpendicular to edges`.*\n",
    "    - ***Non-maximum suppression** – Identified the edge by going through gradient direction to thin the edges of the image.*\n",
    "    - ***Double threshold** –  to identify the strong, weak and irrelevant pixels in the images. Pixels that are above in the `maxThreshold --> sure to be edges` | Pixels that are below in the `minThreshold --> sure to be non-edges(discarded)`*\n",
    "    - ***Hysteresis thresholding** – pixels within hysterisis are considered as edges if they `connected to sure edges` or discard if they are `connected to non edges`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rising-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgCanny = cv.Canny(imgGray, 100, 150) # cv.Canny (src img, minThreshold, maxThreshold)\n",
    "\n",
    "cv.imshow(\"Canny Image\", imgCanny)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Dilation***\n",
    "\n",
    "- This operations consists of convolving an `image` with some `kernel`. It can be any size and have an anchor point(usually the center).\n",
    "- While convolving, compute the `maximum pixel` value of the image overlapped by the kernal and `replace it with the pixel value at the anchor pixel.`\n",
    "- The `thickness of the bright area will grow` due to that.\n",
    "\n",
    "\n",
    "*for the cv.dilate() we input our image, selected kernel and the itterations.(that means thickness)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "breathing-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "imgDilated = cv.dilate(imgCanny, kernel, iterations=1) \n",
    "\n",
    "cv.imshow(\"Dilated Image\", imgDilated)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Erosion***\n",
    "\n",
    "- This operations consists of convolving an `image` with some `kernel`. It can be any size and have an anchor point(usually the center).\n",
    "- While convolving, compute the `minimum pixel` value of the image overlapped by the kernal and `replace it with the pixel value at the anchor pixel.`\n",
    "- The `bright areas of the image get thinner`, whereas the `dark zones gets bigger` due to that.\n",
    "\n",
    "\n",
    "*for the cv.dilate() we input our image, selected kernel and the itterations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "imgEroded = cv.erode(imgDilated, kernel, iterations=1) \n",
    "\n",
    "cv.imshow(\"Eroded Image\", imgEroded)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chapter 3 :Resizing & Cropping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In OpenCV, there is convention about the origin. Always origin is located at top left corner......................\n",
    "- When we Resizing the image it will not be increase or decrese the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "imgNew = cv.imread('resources/car.jpg')\n",
    "print(imgNew.shape) # outputs (Height, Width, no of color planes(RGB))\n",
    "\n",
    "imgResize = cv.resize(imgNew, (1200,700)) # 1st parameter is width, 2nd one is height\n",
    "\n",
    "imgCrop = imgResize[0:400, 200:700] # 1st param = croping region of height ....|.... 2nd parm = croping region for width\n",
    "\n",
    "cv.imshow(\"Resized Image\", imgResize)\n",
    "cv.imshow(\"Cropped Image\", imgCrop)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chapter 4 :Shapes & Texts** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff9c3df18c39e40a632fe67bd3f2effcf292bf7152cebacfc692487f5f951f29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
